
@article{keele_causal_2021,
	title = {Causal interaction and effect modification: same model, different concepts},
	volume = {9},
	issn = {2049-8470, 2049-8489},
	shorttitle = {Causal interaction and effect modification},
	url = {https://www.cambridge.org/core/journals/political-science-research-and-methods/article/abs/causal-interaction-and-effect-modification-same-model-different-concepts/1036031FB5777BC435934E3684685A49},
	doi = {10.1017/psrm.2020.12},
	abstract = {Social scientists use the concept of interactions to study effect dependency. In the causal inference literature, interaction terms may be used in two distinct type of analysis. The first type of analysis focuses on causal interactions, where the analyst is interested in whether two treatments have differing effects when both are administered. The second type of analysis focuses on effect modification, where the analyst investigates whether the effect of a single treatment varies across levels of a baseline covariate. While both forms of interaction analysis are typically conducted using the same type of statistical model, the identification assumptions for these two types of analysis are very different. In this paper, we clarify the difference between these two types of interaction analysis. We demonstrate that this distinction is mostly ignored in the political science literature. We conclude with a review of several applications where we show that the form of the interaction is critical to proper interpretation of empirical results.},
	language = {en},
	number = {3},
	urldate = {2021-10-13},
	journal = {Political Science Research and Methods},
	author = {Keele, Luke and Stevenson, Randolph T.},
	month = jul,
	year = {2021},
	keywords = {Causal inference, Interaction, effect modification},
	pages = {641--649},
}

@article{brambor_understanding_2006,
	title = {Understanding {Interaction} {Models}: {Improving} {Empirical} {Analyses}},
	volume = {14},
	issn = {1047-1987},
	shorttitle = {Understanding {Interaction} {Models}},
	url = {https://www.jstor.org/stable/25791835},
	abstract = {Multiplicative interaction models are common in the quantitative political science literature. This is so for good reason. Institutional arguments frequently imply that the relationship between political inputs and outcomes varies depending on the institutional context. Models of strategic interaction typically produce conditional hypotheses as well. Although conditional hypotheses are ubiquitous in political science and multiplicative interaction models have been found to capture their intuition quite well, a survey of the top three political science journals from 1998 to 2002 suggests that the execution of these models is often flawed and inferential errors are common. We believe that considerable progress in our understanding of the political world can occur if scholars follow the simple checklist of dos and don'ts for using multiplicative interaction models presented in this article. Only 10\% of the articles in our survey followed the checklist.},
	number = {1},
	urldate = {2021-10-13},
	journal = {Political Analysis},
	author = {Brambor, Thomas and Clark, William Roberts and Golder, Matt},
	year = {2006},
	pages = {63--82},
}



@article{gigerenzer_statistical_2018,
	title = {Statistical {Rituals}: {The} {Replication} {Delusion} and {How} {We} {Got} {There}},
	volume = {1},
	issn = {2515-2459},
	shorttitle = {Statistical {Rituals}},
	url = {https://doi.org/10.1177/2515245918771329},
	doi = {10.1177/2515245918771329},
	abstract = {The {\textquotedblleft}replication crisis{\textquotedblright} has been attributed to misguided external incentives gamed by researchers (the strategic-game hypothesis). Here, I want to draw attention to a complementary internal factor, namely, researchers{\textquoteright} widespread faith in a statistical ritual and associated delusions (the statistical-ritual hypothesis). The {\textquotedblleft}null ritual,{\textquotedblright} unknown in statistics proper, eliminates judgment precisely at points where statistical theories demand it. The crucial delusion is that the p value specifies the probability of a successful replication (i.e., 1 {\textendash} p), which makes replication studies appear to be superfluous. A review of studies with 839 academic psychologists and 991 students shows that the replication delusion existed among 20\% of the faculty teaching statistics in psychology, 39\% of the professors and lecturers, and 66\% of the students. Two further beliefs, the illusion of certainty (e.g., that statistical significance proves that an effect exists) and Bayesian wishful thinking (e.g., that the probability of the alternative hypothesis being true is 1 {\textendash} p), also make successful replication appear to be certain or almost certain, respectively. In every study reviewed, the majority of researchers (56\%{\textendash}97\%) exhibited one or more of these delusions. Psychology departments need to begin teaching statistical thinking, not rituals, and journal editors should no longer accept manuscripts that report results as {\textquotedblleft}significant{\textquotedblright} or {\textquotedblleft}not significant.{\textquotedblright}},
	language = {en},
	number = {2},
	urldate = {2022-08-25},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Gigerenzer, Gerd},
	month = jun,
	year = {2018},
	note = {Publisher: SAGE Publications Inc},
	keywords = {illusion of certainty, null ritual, p value, p-hacking, replication},
	pages = {198--218}
}

